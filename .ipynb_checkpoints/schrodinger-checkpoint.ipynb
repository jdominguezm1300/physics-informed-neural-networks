{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "schrodinger_14.07.2021.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvlsbgRPEDnjLqWMm1QmD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdominguezm1300/physics-informed-neural-networks/blob/main/schrodinger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gXPNvgTu8-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d224c5e-f0d3-4c29-f744-981487fd93cb"
      },
      "source": [
        "!pip install pyDOE\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8n5-c3vd8M"
      },
      "source": [
        "#Liberias requeridas\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy import optimize\n",
        "from scipy.interpolate import griddata\n",
        "from pyDOE import lhs\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from datetime import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "np.random.seed(123)\n",
        "tf.random.set_seed(123)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lueps3mhwC78"
      },
      "source": [
        "class dummy(object):\n",
        "  pass\n",
        "\n",
        "class Struct(dummy):\n",
        "  def __getattribute__(self, key):\n",
        "    if key == '__dict__':\n",
        "      return super(dummy, self).__getattribute__('__dict__')\n",
        "    return self.__dict__.get(key, 0)\n",
        "#Clase del modelo de red profunda informada por la física\n",
        "class PhysicsInformedNN():\n",
        "  #__init__\n",
        "  #Descripción: Constructor de la clase del modelo de la red neuronal profunda\n",
        "  def __init__(self,N0,N_b,N_f,layers,tf_epochs,tf_lr,tf_b1,tf_eps,nt_epochs,nt_lr,nt_ncorr,log_frequency, X_f,tb,ub,lb):\n",
        "    #X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
        "    self.X_lb =tf.convert_to_tensor(np.concatenate((0*tb + lb[0], tb), 1),dtype=tf.float64) # (lb[0], tb)\n",
        "    self.X_ub =tf.convert_to_tensor(np.concatenate((0*tb + ub[0], tb), 1),dtype=tf.float64) # (ub[0], tb)\n",
        "    self.x_f = tf.convert_to_tensor(X_f[:,0:1], dtype=tf.float64)\n",
        "    self.t_f = tf.convert_to_tensor(X_f[:,1:2], dtype=tf.float64)\n",
        "    #Inicialización de los Hiperparámetros de la red neuronal profunda\n",
        "    self.nt_config = Struct()\n",
        "    self.nt_config.learningRate = nt_lr\n",
        "    self.nt_config.maxIter = nt_epochs\n",
        "    self.nt_config.nCorrection = nt_ncorr\n",
        "    self.nt_config.tolFun = 1.0 * np.finfo(float).eps\n",
        "    self.tf_epochs = tf_epochs\n",
        "    #Inicialización del optimizador Adam\n",
        "    self.tf_optimizer = tf.keras.optimizers.Adam(learning_rate=tf_lr,beta_1=tf_b1,epsilon=tf_eps)\n",
        "    tf.keras.backend.set_floatx('float64')\n",
        "    #Creación del Modelo de la red neuronal profunda\n",
        "    self.model = tf.keras.Sequential()\n",
        "    #Inicialización de la capa de entrada\n",
        "    self.model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    #Inicialización de las capas ocultas\n",
        "    self.model.add(tf.keras.layers.Lambda(lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:-1]:\n",
        "      self.model.add(tf.keras.layers.Dense(width, activation=tf.nn.tanh,kernel_initializer=\"glorot_normal\"))\n",
        "      self.model.add(tf.keras.layers.Dense(layers[-1], activation=None,kernel_initializer=\"glorot_normal\"))\n",
        "    # Creación de arreglos del tamaño de  weights/biases para su descomposición\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    self.epoch_nt=tf_epochs\n",
        "    self.loss_train_tf=[]\n",
        "    self.loss_train_nt=[]\n",
        "    self.start_time = time.time()\n",
        "    self.prev_time = self.start_time\n",
        "    self.frequency = log_frequency\n",
        "\n",
        "    \n",
        "  #net_uv\n",
        "  #Descripción: Neurona para el calculo de u(t,x) y v(t,x)\n",
        "  def net_uv(self,X):\n",
        "    x = X[:, 0:1]\n",
        "    t = X[:, 1:2]\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      tape.watch(x)\n",
        "      tape.watch(t)\n",
        "      Xtemp = tf.concat([x,t],axis=1)\n",
        "      uv = self.model(Xtemp)\n",
        "      u = uv[:,0:1]\n",
        "      v = uv[:,1:2]\n",
        "    #Calculo de los gradientes\n",
        "    u_x = tape.gradient(u, x)\n",
        "    v_x = tape.gradient(v, x)\n",
        "    del tape\n",
        "    return u, v, u_x, v_x\n",
        "\n",
        "  #net_f_uv\n",
        "  #Decrioción: Neurona para el calculo de f(t,x)\n",
        "  def net_f_uv(self):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      tape.watch(self.x_f)\n",
        "      tape.watch(self.t_f)\n",
        "      X_f = tf.concat([self.x_f, self.t_f], axis=1)\n",
        "      u, v, u_x, v_x = self.net_uv(X_f)\n",
        "    #Calculo de gradientes\n",
        "    u_t = tape.gradient(u, self.t_f)\n",
        "    v_t = tape.gradient(v, self.t_f)\n",
        "    u_xx = tape.gradient(u_x, self.x_f)\n",
        "    v_xx = tape.gradient(v_x, self.x_f)\n",
        "    del tape\n",
        "    f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v\n",
        "    f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u   \n",
        "    return f_u, f_v\n",
        "  #loss\n",
        "  #Descripción: Función de perdida, calcula el error cuadratico medio\n",
        "  #             El eror MSE es la suma del error en MSE0,MSEB y MSF\n",
        "  def loss(self,uv,uv_pred ):\n",
        "    u0 = uv[:, 0:1]\n",
        "    v0 = uv[:, 1:2]\n",
        "    u0_pred = uv_pred[:, 0:1]\n",
        "    v0_pred = uv_pred[:, 1:2]\n",
        "    u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.X_lb)\n",
        "    u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.X_ub)\n",
        "    f_u_pred, f_v_pred = self.net_f_uv()\n",
        "    mse_0 = tf.reduce_mean(tf.square(u0 - u0_pred)) + tf.reduce_mean(tf.square(v0 - v0_pred))\n",
        "    mse_b = tf.reduce_mean(tf.square(u_lb_pred - u_ub_pred)) + tf.reduce_mean(tf.square(v_lb_pred - v_ub_pred)) + tf.reduce_mean(tf.square(u_x_lb_pred - u_x_ub_pred)) + tf.reduce_mean(tf.square(v_x_lb_pred - v_x_ub_pred))\n",
        "    mse_f = tf.reduce_mean(tf.square(f_u_pred)) + tf.reduce_mean(tf.square(f_v_pred))\n",
        "    loss_value=mse_0 + mse_b + mse_f\n",
        "    return loss_value\n",
        "\n",
        "  #predict\n",
        "  #Descripción: Función de predicción de la solución de la ecuación \n",
        "  #             de schrodinger con la red profunda entrenada\n",
        "  def predict(self, X_star):\n",
        "    h_pred = self.model(X_star)\n",
        "    u_pred = h_pred[:, 0:1]\n",
        "    v_pred = h_pred[:, 1:2]\n",
        "    return u_pred.numpy(), v_pred.numpy()\n",
        "\n",
        "  #tf_optimization\n",
        "  #Descripción: Optimización con Adam\n",
        "  def tf_optimization(self, X_u, u):\n",
        "    print(f\"-- Starting Adam optimization --\")\n",
        "    for epoch in range(self.tf_epochs):\n",
        "      loss_value = self.tf_optimization_step(X_u, u)\n",
        "      self.loss_train_tf.append([epoch,loss_value.numpy()])\n",
        "      self.log_train_epoch(epoch, loss_value,is_iter=False)\n",
        "  \n",
        "  #tf_optimization_step\n",
        "  #Descripción: La función regresa el error obtenido despúes de aplicar \n",
        "  #             el optimizador Adam en una epoca\n",
        "  def tf_optimization_step(self, X_u, u):\n",
        "    loss_value, grads = self.grad(X_u, u)\n",
        "    self.tf_optimizer.apply_gradients(zip(grads,self.model.trainable_variables ))\n",
        "    return loss_value\n",
        "\n",
        "  #grad\n",
        "  #Descripción: La función regresa el error obtenido y \n",
        "  #             el caculo de los gradientes de las variables entrenables\n",
        "  def grad(self, X, u):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.loss(u, self.model(X))\n",
        "      grads = tape.gradient(loss_value, self.model.trainable_variables)\n",
        "    return loss_value, grads\n",
        "\n",
        "  #log_train_epoch\n",
        "  #Descripción:La función imprime la epoca de entrenamiendo, el tiempo transcurrido y el error\n",
        "  def log_train_epoch(self,epoch, loss, is_iter,custom=\"\"):\n",
        "    if epoch % self.frequency == 0:\n",
        "      name = 'nt_epoch' if is_iter else 'tf_epoch'\n",
        "      print(f\"{name} = {epoch:6d}  \" + f\"elapsed = {self.get_elapsed()} \" + f\"(+{self.get_epoch_duration()})  \" + f\"loss = {loss:.4e}  \" + custom)\n",
        "  \n",
        "  #get_epoch_duration\n",
        "  #Descripción: La función regresa el tiempo de entrenamiento de una epoca\n",
        "  def get_epoch_duration(self):\n",
        "        now = time.time()\n",
        "        edur = datetime.fromtimestamp(now - self.prev_time) \\\n",
        "            .strftime(\"%S.%f\")[:-5]\n",
        "        self.prev_time = now\n",
        "        return edur\n",
        "\n",
        "  #get_elapsed\n",
        "  #Descripción: La función regresa el tiempo transcurrido en una epoca \n",
        "  def get_elapsed(self):\n",
        "    return datetime.fromtimestamp(time.time() - self.start_time).strftime(\"%M:%S\")          \n",
        "\n",
        "  #set_weights\n",
        "  #Descripción: La función actualiza los pesos sinapticos de la red\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "\n",
        "  #get_weights\n",
        "  #Descripción:La función obtiene los pesos sinapticos de las capas de la red con sus bias\n",
        "  def get_weights(self):\n",
        "    w = []\n",
        "    for layer in self.model.layers[1:]:\n",
        "      weights_biases = layer.get_weights()\n",
        "      weights = weights_biases[0].flatten()\n",
        "      biases = weights_biases[1]\n",
        "      self.sizes_w.append(len(weights))\n",
        "      self.sizes_b.append(len(biases))\n",
        "      w.extend(weights)\n",
        "      w.extend(biases)\n",
        "    w = tf.convert_to_tensor(w, dtype=tf.float64)\n",
        "    return w\n",
        "\n",
        "  #get_loss_and_flat_grad\n",
        "  #Descripción:La función regresa el error y los gradiantes de las variables entrenables\n",
        "  def get_loss_and_flat_grad(self, X, u):\n",
        "    #loss_and_flat_grad\n",
        "    #Entrada: La función recibe un vector de pesos\n",
        "    #Descripción: La función llama a set_weights para actualizar los pesos,\n",
        "    #             despúes obtiene el error y calcula los gradientes de las variables entrenables\n",
        "    def loss_and_flat_grad(w):\n",
        "      grad_flat = []\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        loss_value = self.loss(u, self.model(X))\n",
        "        self.loss_train_nt.append([self.epoch_nt,loss_value.numpy()])\n",
        "      grad = tape.gradient(loss_value, self.model.trainable_variables)\n",
        "      #Se ordenan los gradientes en un tensor\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat = tf.concat(grad_flat, 0)\n",
        "      self.log_train_epoch(self.epoch_nt, loss_value,is_iter=True)\n",
        "      self.epoch_nt+=1\n",
        "      return loss_value, grad_flat\n",
        "    return loss_and_flat_grad\n",
        "\n",
        "  #nt_optimization\n",
        "  #Descripción: La función realiza la optimización con LBFGS\n",
        "  #             la función que regresa el error y los gradiantes es loss_and_flat_grad en una tupla\n",
        "  #             y la posición inicial del optimizador son los pesos resultantes de la optimización con Adam  \n",
        "  def nt_optimization(self, X_u, u):\n",
        "    print(f\"-- Starting LBFGS optimization --\")\n",
        "    loss_and_flat_grad = self.get_loss_and_flat_grad(X_u, u)\n",
        " \n",
        "    results=tfp.optimizer.lbfgs_minimize(\n",
        "        loss_and_flat_grad,\n",
        "        initial_position=self.get_weights(),\n",
        "        num_correction_pairs=self.nt_config.nCorrection,\n",
        "        max_iterations=self.nt_config.maxIter,\n",
        "        f_relative_tolerance=self.nt_config.tolFun,\n",
        "        tolerance=self.nt_config.tolFun,\n",
        "        parallel_iterations=10)\n",
        "    print('L-BFGS Results')\n",
        "    print('Converged:', results.converged)\n",
        "    print('Location of the minimum:', results.position)\n",
        "    print('Number of iterations:', results.num_iterations)\n",
        "   \n",
        "  #fit\n",
        "  #Descripción: La función realiza el entrenamiento de la red con \n",
        "  #             los optimizadores Adam y LBFGS\n",
        "  def fit(self, X_u, u):\n",
        "    print(\"\\nTraining started\")\n",
        "    print(\"================\")\n",
        "    print(self.model.summary())\n",
        "    # Creating the tensors\n",
        "    X_u = tf.convert_to_tensor(X_u,dtype=tf.float64)\n",
        "    u =tf.convert_to_tensor(u,dtype=tf.float64)\n",
        "    # Optimizing\n",
        "    self.tf_optimization(X_u, u)\n",
        "    self.nt_optimization(X_u, u)\n",
        "    print(\"==================\")\n",
        "    print(f\"Training finished (epochs {self.tf_epochs+self.nt_config.maxIter}): \" + f\"duration = {self.get_elapsed()}  \"  )\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZIQxvUTgpoH"
      },
      "source": [
        "#Se establecen los Hiperparametros de la red\n",
        "N0 = 50\n",
        "N_b = 50\n",
        "N_f = 20000\n",
        "#Capas\n",
        "layers = [2, 100, 100, 100, 100, 2]\n",
        "#Epocas\n",
        "tf_epochs=1000\n",
        "tf_lr=0.025\n",
        "tf_b1=0.99\n",
        "tf_eps=1e-1\n",
        "nt_epochs=1500\n",
        "nt_lr=1.2\n",
        "nt_ncorr=50\n",
        "#Frecuencia para imprimir los resultados\n",
        "log_frequency=10\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh7YmBKjgyzM"
      },
      "source": [
        "#Carga de los datos\n",
        "noise=0.0\n",
        "data = scipy.io.loadmat('NLS.mat')\n",
        "lb = np.array([-5.0, 0.0])\n",
        "ub = np.array([5.0, np.pi/2])\n",
        "t = data['tt'].flatten()[:,None]\n",
        "x = data['x'].flatten()[:,None]\n",
        "Exact = data['uu']\n",
        "Exact_u = np.real(Exact)\n",
        "Exact_v = np.imag(Exact)\n",
        "Exact_h = np.sqrt(Exact_u**2 + Exact_v**2)\n",
        "X, T = np.meshgrid(x,t)\n",
        "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "u_star = Exact_u.T.flatten()[:,None]\n",
        "v_star = Exact_v.T.flatten()[:,None]\n",
        "h_star = Exact_h.T.flatten()[:,None]    \n",
        "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
        "x0 = x[idx_x,:]\n",
        "u0 = Exact_u[idx_x,0:1]\n",
        "v0 = Exact_v[idx_x,0:1]    \n",
        "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
        "tb = t[idx_t,:]\n",
        "X_f = lb + (ub-lb)*lhs(2, N_f)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC0yHQkbxLyp",
        "outputId": "90b86ef8-cfb6-4ec8-9f81-3a989394e171"
      },
      "source": [
        "pinn = PhysicsInformedNN(N0,N_b,N_f,layers,tf_epochs,tf_lr,tf_b1,tf_eps,nt_epochs,nt_lr,nt_ncorr,log_frequency, X_f,tb,ub,lb)\n",
        "pinn.fit(x0, tf.concat([u0, v0], axis=1))\n",
        "#Se realiza la predicción una vez entrenada la red\n",
        "u_pred, v_pred = pinn.predict(X_star)\n",
        "h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
        "#Se calcula el erro en la predicción\n",
        "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
        "error_h = np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)\n",
        "\n",
        "print('Error u: %e' % (error_u))\n",
        "print('Error v: %e' % (error_v))\n",
        "print('Error h: %e' % (error_h))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda (Lambda)              (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               300       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               300       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               300       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               300       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 2,008\n",
            "Trainable params: 2,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "-- Starting Adam optimization --\n",
            "tf_epoch =      0  elapsed = 00:03 (+03.3)  loss = 6.3900e-01  \n",
            "tf_epoch =     10  elapsed = 00:29 (+26.3)  loss = 3.7367e-01  \n",
            "tf_epoch =     20  elapsed = 00:55 (+26.2)  loss = 4.7297e-01  \n",
            "tf_epoch =     30  elapsed = 01:22 (+26.2)  loss = 3.7002e-01  \n",
            "tf_epoch =     40  elapsed = 01:48 (+26.3)  loss = 4.0691e-01  \n",
            "tf_epoch =     50  elapsed = 02:14 (+26.4)  loss = 4.1896e-01  \n",
            "tf_epoch =     60  elapsed = 02:41 (+26.2)  loss = 3.8312e-01  \n",
            "tf_epoch =     70  elapsed = 03:07 (+26.3)  loss = 3.7291e-01  \n",
            "tf_epoch =     80  elapsed = 03:33 (+26.3)  loss = 4.0223e-01  \n",
            "tf_epoch =     90  elapsed = 04:00 (+26.3)  loss = 3.8348e-01  \n",
            "tf_epoch =    100  elapsed = 04:26 (+26.6)  loss = 3.6731e-01  \n",
            "tf_epoch =    110  elapsed = 04:53 (+26.2)  loss = 3.8299e-01  \n",
            "tf_epoch =    120  elapsed = 05:19 (+26.2)  loss = 3.8998e-01  \n",
            "tf_epoch =    130  elapsed = 05:45 (+26.1)  loss = 3.7643e-01  \n",
            "tf_epoch =    140  elapsed = 06:11 (+26.0)  loss = 3.6424e-01  \n",
            "tf_epoch =    150  elapsed = 06:37 (+25.9)  loss = 3.7192e-01  \n",
            "tf_epoch =    160  elapsed = 07:03 (+26.0)  loss = 3.7735e-01  \n",
            "tf_epoch =    170  elapsed = 07:29 (+26.1)  loss = 3.6316e-01  \n",
            "tf_epoch =    180  elapsed = 07:56 (+26.2)  loss = 3.5847e-01  \n",
            "tf_epoch =    190  elapsed = 08:22 (+26.3)  loss = 3.6551e-01  \n",
            "tf_epoch =    200  elapsed = 08:48 (+26.2)  loss = 3.6552e-01  \n",
            "tf_epoch =    210  elapsed = 09:14 (+26.2)  loss = 3.5741e-01  \n",
            "tf_epoch =    220  elapsed = 09:41 (+26.4)  loss = 3.5612e-01  \n",
            "tf_epoch =    230  elapsed = 10:07 (+26.1)  loss = 3.5963e-01  \n",
            "tf_epoch =    240  elapsed = 10:33 (+26.1)  loss = 3.5277e-01  \n",
            "tf_epoch =    250  elapsed = 10:59 (+26.0)  loss = 3.4743e-01  \n",
            "tf_epoch =    260  elapsed = 11:25 (+26.1)  loss = 3.4972e-01  \n",
            "tf_epoch =    270  elapsed = 11:52 (+26.1)  loss = 3.4878e-01  \n",
            "tf_epoch =    280  elapsed = 12:18 (+26.0)  loss = 3.3994e-01  \n",
            "tf_epoch =    290  elapsed = 12:44 (+26.1)  loss = 3.3049e-01  \n",
            "tf_epoch =    300  elapsed = 13:10 (+26.1)  loss = 3.2379e-01  \n",
            "tf_epoch =    310  elapsed = 13:36 (+25.9)  loss = 3.0544e-01  \n",
            "tf_epoch =    320  elapsed = 14:02 (+26.0)  loss = 2.9987e-01  \n",
            "tf_epoch =    330  elapsed = 14:28 (+26.0)  loss = 3.0207e-01  \n",
            "tf_epoch =    340  elapsed = 14:54 (+25.9)  loss = 3.1588e-01  \n",
            "tf_epoch =    350  elapsed = 15:20 (+25.9)  loss = 3.0043e-01  \n",
            "tf_epoch =    360  elapsed = 15:46 (+25.9)  loss = 2.9145e-01  \n",
            "tf_epoch =    370  elapsed = 16:12 (+26.1)  loss = 2.8806e-01  \n",
            "tf_epoch =    380  elapsed = 16:38 (+26.1)  loss = 2.9481e-01  \n",
            "tf_epoch =    390  elapsed = 17:04 (+26.2)  loss = 2.9442e-01  \n",
            "tf_epoch =    400  elapsed = 17:30 (+26.1)  loss = 2.9121e-01  \n",
            "tf_epoch =    410  elapsed = 17:57 (+26.3)  loss = 2.8414e-01  \n",
            "tf_epoch =    420  elapsed = 18:23 (+26.2)  loss = 2.7595e-01  \n",
            "tf_epoch =    430  elapsed = 18:49 (+26.0)  loss = 2.7187e-01  \n",
            "tf_epoch =    440  elapsed = 19:15 (+26.2)  loss = 2.7504e-01  \n",
            "tf_epoch =    450  elapsed = 19:42 (+26.2)  loss = 2.7575e-01  \n",
            "tf_epoch =    460  elapsed = 20:08 (+26.2)  loss = 2.7057e-01  \n",
            "tf_epoch =    470  elapsed = 20:34 (+26.2)  loss = 2.6716e-01  \n",
            "tf_epoch =    480  elapsed = 21:00 (+26.3)  loss = 2.6764e-01  \n",
            "tf_epoch =    490  elapsed = 21:27 (+26.2)  loss = 2.6807e-01  \n",
            "tf_epoch =    500  elapsed = 21:53 (+26.2)  loss = 2.6864e-01  \n",
            "tf_epoch =    510  elapsed = 22:19 (+26.5)  loss = 2.6799e-01  \n",
            "tf_epoch =    520  elapsed = 22:46 (+26.0)  loss = 2.6559e-01  \n",
            "tf_epoch =    530  elapsed = 23:12 (+26.1)  loss = 2.6365e-01  \n",
            "tf_epoch =    540  elapsed = 23:38 (+26.1)  loss = 2.6437e-01  \n",
            "tf_epoch =    550  elapsed = 24:04 (+26.0)  loss = 2.6521e-01  \n",
            "tf_epoch =    560  elapsed = 24:30 (+26.0)  loss = 2.6418e-01  \n",
            "tf_epoch =    570  elapsed = 24:56 (+26.0)  loss = 2.6196e-01  \n",
            "tf_epoch =    580  elapsed = 25:22 (+26.0)  loss = 2.6063e-01  \n",
            "tf_epoch =    590  elapsed = 25:48 (+25.9)  loss = 2.6067e-01  \n",
            "tf_epoch =    600  elapsed = 26:14 (+26.1)  loss = 2.6071e-01  \n",
            "tf_epoch =    610  elapsed = 26:40 (+26.1)  loss = 2.5993e-01  \n",
            "tf_epoch =    620  elapsed = 27:07 (+26.1)  loss = 2.5864e-01  \n",
            "tf_epoch =    630  elapsed = 27:33 (+26.0)  loss = 2.5733e-01  \n",
            "tf_epoch =    640  elapsed = 27:59 (+26.2)  loss = 2.5686e-01  \n",
            "tf_epoch =    650  elapsed = 28:25 (+26.2)  loss = 2.5703e-01  \n",
            "tf_epoch =    660  elapsed = 28:51 (+26.3)  loss = 2.5658e-01  \n",
            "tf_epoch =    670  elapsed = 29:18 (+26.3)  loss = 2.5557e-01  \n",
            "tf_epoch =    680  elapsed = 29:44 (+26.2)  loss = 2.5513e-01  \n",
            "tf_epoch =    690  elapsed = 30:10 (+26.1)  loss = 2.5519e-01  \n",
            "tf_epoch =    700  elapsed = 30:36 (+26.1)  loss = 2.5506e-01  \n",
            "tf_epoch =    710  elapsed = 31:02 (+26.1)  loss = 2.5451e-01  \n",
            "tf_epoch =    720  elapsed = 31:28 (+26.0)  loss = 2.5375e-01  \n",
            "tf_epoch =    730  elapsed = 31:54 (+25.9)  loss = 2.5310e-01  \n",
            "tf_epoch =    740  elapsed = 32:20 (+26.0)  loss = 2.5281e-01  \n",
            "tf_epoch =    750  elapsed = 32:47 (+26.2)  loss = 2.5283e-01  \n",
            "tf_epoch =    760  elapsed = 33:13 (+26.1)  loss = 2.5237e-01  \n",
            "tf_epoch =    770  elapsed = 33:39 (+26.0)  loss = 2.5194e-01  \n",
            "tf_epoch =    780  elapsed = 34:05 (+26.2)  loss = 2.5149e-01  \n",
            "tf_epoch =    790  elapsed = 34:31 (+26.2)  loss = 2.5125e-01  \n",
            "tf_epoch =    800  elapsed = 34:58 (+26.2)  loss = 2.5087e-01  \n",
            "tf_epoch =    810  elapsed = 35:24 (+26.2)  loss = 2.5042e-01  \n",
            "tf_epoch =    820  elapsed = 35:50 (+26.1)  loss = 2.5002e-01  \n",
            "tf_epoch =    830  elapsed = 36:16 (+26.4)  loss = 2.4977e-01  \n",
            "tf_epoch =    840  elapsed = 36:43 (+26.2)  loss = 2.4957e-01  \n",
            "tf_epoch =    850  elapsed = 37:09 (+26.3)  loss = 2.4941e-01  \n",
            "tf_epoch =    860  elapsed = 37:35 (+26.2)  loss = 2.4905e-01  \n",
            "tf_epoch =    870  elapsed = 38:01 (+26.0)  loss = 2.4876e-01  \n",
            "tf_epoch =    880  elapsed = 38:27 (+26.0)  loss = 2.4856e-01  \n",
            "tf_epoch =    890  elapsed = 38:54 (+26.2)  loss = 2.4850e-01  \n",
            "tf_epoch =    900  elapsed = 39:20 (+26.4)  loss = 2.4831e-01  \n",
            "tf_epoch =    910  elapsed = 39:46 (+26.1)  loss = 2.4818e-01  \n",
            "tf_epoch =    920  elapsed = 40:12 (+26.0)  loss = 2.4806e-01  \n",
            "tf_epoch =    930  elapsed = 40:38 (+25.9)  loss = 2.4800e-01  \n",
            "tf_epoch =    940  elapsed = 41:04 (+25.9)  loss = 2.4782e-01  \n",
            "tf_epoch =    950  elapsed = 41:30 (+26.0)  loss = 2.4762e-01  \n",
            "tf_epoch =    960  elapsed = 41:56 (+25.7)  loss = 2.4750e-01  \n",
            "tf_epoch =    970  elapsed = 42:22 (+25.9)  loss = 2.4735e-01  \n",
            "tf_epoch =    980  elapsed = 42:48 (+26.0)  loss = 2.4717e-01  \n",
            "tf_epoch =    990  elapsed = 43:14 (+25.9)  loss = 2.4696e-01  \n",
            "-- Starting LBFGS optimization --\n",
            "nt_epoch =   1000  elapsed = 43:40 (+26.0)  loss = 2.4673e-01  \n",
            "nt_epoch =   1010  elapsed = 44:06 (+26.4)  loss = 2.4655e-01  \n",
            "nt_epoch =   1020  elapsed = 44:33 (+26.6)  loss = 2.4606e-01  \n",
            "nt_epoch =   1030  elapsed = 45:00 (+26.5)  loss = 2.4356e-01  \n",
            "nt_epoch =   1040  elapsed = 45:26 (+26.8)  loss = 3.2702e-01  \n",
            "nt_epoch =   1050  elapsed = 45:53 (+26.5)  loss = 2.2855e-01  \n",
            "nt_epoch =   1060  elapsed = 46:20 (+26.7)  loss = 3.2435e-01  \n",
            "nt_epoch =   1070  elapsed = 46:46 (+26.6)  loss = 2.1444e-01  \n",
            "nt_epoch =   1080  elapsed = 47:13 (+26.6)  loss = 2.1010e-01  \n",
            "nt_epoch =   1090  elapsed = 47:39 (+26.3)  loss = 2.0616e-01  \n",
            "nt_epoch =   1100  elapsed = 48:06 (+26.4)  loss = 2.0394e-01  \n",
            "nt_epoch =   1110  elapsed = 48:32 (+26.3)  loss = 2.0105e-01  \n",
            "nt_epoch =   1120  elapsed = 48:58 (+26.3)  loss = 1.9902e-01  \n",
            "nt_epoch =   1130  elapsed = 49:25 (+26.5)  loss = 1.9462e-01  \n",
            "nt_epoch =   1140  elapsed = 49:51 (+26.5)  loss = 1.9450e-01  \n",
            "nt_epoch =   1150  elapsed = 50:18 (+26.6)  loss = 1.9265e-01  \n",
            "nt_epoch =   1160  elapsed = 50:44 (+26.2)  loss = 1.9161e-01  \n",
            "nt_epoch =   1170  elapsed = 51:11 (+26.5)  loss = 1.9118e-01  \n",
            "nt_epoch =   1180  elapsed = 51:38 (+26.5)  loss = 1.8954e-01  \n",
            "nt_epoch =   1190  elapsed = 52:04 (+26.4)  loss = 1.8906e-01  \n",
            "nt_epoch =   1200  elapsed = 52:31 (+26.4)  loss = 1.9678e-01  \n",
            "nt_epoch =   1210  elapsed = 52:57 (+26.3)  loss = 2.0196e-01  \n",
            "nt_epoch =   1220  elapsed = 53:23 (+26.4)  loss = 1.8348e-01  \n",
            "nt_epoch =   1230  elapsed = 53:50 (+26.4)  loss = 1.8578e-01  \n",
            "nt_epoch =   1240  elapsed = 54:16 (+26.4)  loss = 1.7994e-01  \n",
            "nt_epoch =   1250  elapsed = 54:43 (+26.5)  loss = 1.7230e-01  \n",
            "nt_epoch =   1260  elapsed = 55:09 (+26.6)  loss = 1.6787e-01  \n",
            "nt_epoch =   1270  elapsed = 55:36 (+26.7)  loss = 1.6555e-01  \n",
            "nt_epoch =   1280  elapsed = 56:03 (+26.7)  loss = 1.6941e-01  \n",
            "nt_epoch =   1290  elapsed = 56:30 (+26.6)  loss = 1.6212e-01  \n",
            "nt_epoch =   1300  elapsed = 56:56 (+26.4)  loss = 1.6138e-01  \n",
            "nt_epoch =   1310  elapsed = 57:23 (+26.5)  loss = 1.6796e-01  \n",
            "nt_epoch =   1320  elapsed = 57:49 (+26.4)  loss = 1.5762e-01  \n",
            "nt_epoch =   1330  elapsed = 58:15 (+26.3)  loss = 1.5429e-01  \n",
            "nt_epoch =   1340  elapsed = 58:42 (+26.6)  loss = 1.5200e-01  \n",
            "nt_epoch =   1350  elapsed = 59:09 (+26.5)  loss = 1.5147e-01  \n",
            "nt_epoch =   1360  elapsed = 59:35 (+26.5)  loss = 1.5051e-01  \n",
            "nt_epoch =   1370  elapsed = 00:02 (+26.6)  loss = 1.4977e-01  \n",
            "nt_epoch =   1380  elapsed = 00:28 (+26.4)  loss = 1.4741e-01  \n",
            "nt_epoch =   1390  elapsed = 00:55 (+26.5)  loss = 1.4445e-01  \n",
            "nt_epoch =   1400  elapsed = 01:22 (+26.6)  loss = 1.4265e-01  \n",
            "nt_epoch =   1410  elapsed = 01:48 (+26.4)  loss = 1.4202e-01  \n",
            "nt_epoch =   1420  elapsed = 02:15 (+26.5)  loss = 1.6785e-01  \n",
            "nt_epoch =   1430  elapsed = 02:41 (+26.5)  loss = 1.3674e-01  \n",
            "nt_epoch =   1440  elapsed = 03:08 (+26.5)  loss = 1.3500e-01  \n",
            "nt_epoch =   1450  elapsed = 03:34 (+26.5)  loss = 1.3160e-01  \n",
            "nt_epoch =   1460  elapsed = 04:01 (+26.4)  loss = 1.2998e-01  \n",
            "nt_epoch =   1470  elapsed = 04:27 (+26.8)  loss = 1.2928e-01  \n",
            "nt_epoch =   1480  elapsed = 04:54 (+26.5)  loss = 1.2718e-01  \n",
            "nt_epoch =   1490  elapsed = 05:21 (+26.5)  loss = 1.2454e-01  \n",
            "nt_epoch =   1500  elapsed = 05:47 (+26.5)  loss = 1.2379e-01  \n",
            "nt_epoch =   1510  elapsed = 06:14 (+26.4)  loss = 1.2347e-01  \n",
            "nt_epoch =   1520  elapsed = 06:40 (+26.3)  loss = 1.2285e-01  \n",
            "nt_epoch =   1530  elapsed = 07:06 (+26.5)  loss = 1.2277e-01  \n",
            "nt_epoch =   1540  elapsed = 07:33 (+26.5)  loss = 1.2219e-01  \n",
            "nt_epoch =   1550  elapsed = 08:00 (+26.6)  loss = 1.2448e-01  \n",
            "nt_epoch =   1560  elapsed = 08:26 (+26.9)  loss = 1.2064e-01  \n",
            "nt_epoch =   1570  elapsed = 08:53 (+26.4)  loss = 1.1943e-01  \n",
            "nt_epoch =   1580  elapsed = 09:20 (+26.6)  loss = 1.1671e-01  \n",
            "nt_epoch =   1590  elapsed = 09:46 (+26.7)  loss = 1.1613e-01  \n",
            "nt_epoch =   1600  elapsed = 10:13 (+26.3)  loss = 1.1577e-01  \n",
            "nt_epoch =   1610  elapsed = 10:39 (+26.3)  loss = 1.1565e-01  \n",
            "nt_epoch =   1620  elapsed = 11:05 (+26.3)  loss = 1.1543e-01  \n",
            "nt_epoch =   1630  elapsed = 11:32 (+26.4)  loss = 1.1509e-01  \n",
            "nt_epoch =   1640  elapsed = 11:58 (+26.2)  loss = 1.1437e-01  \n",
            "nt_epoch =   1650  elapsed = 12:25 (+26.4)  loss = 1.1402e-01  \n",
            "nt_epoch =   1660  elapsed = 12:51 (+26.2)  loss = 1.1377e-01  \n",
            "nt_epoch =   1670  elapsed = 13:17 (+26.4)  loss = 1.1358e-01  \n",
            "nt_epoch =   1680  elapsed = 13:44 (+26.3)  loss = 1.1318e-01  \n",
            "nt_epoch =   1690  elapsed = 14:10 (+26.2)  loss = 1.1297e-01  \n",
            "nt_epoch =   1700  elapsed = 14:36 (+26.4)  loss = 1.1281e-01  \n",
            "nt_epoch =   1710  elapsed = 15:03 (+26.4)  loss = 1.1255e-01  \n",
            "nt_epoch =   1720  elapsed = 15:29 (+26.3)  loss = 1.1227e-01  \n",
            "nt_epoch =   1730  elapsed = 15:56 (+26.4)  loss = 1.1215e-01  \n",
            "nt_epoch =   1740  elapsed = 16:22 (+26.5)  loss = 1.1192e-01  \n",
            "nt_epoch =   1750  elapsed = 16:49 (+26.5)  loss = 1.1164e-01  \n",
            "nt_epoch =   1760  elapsed = 17:15 (+26.6)  loss = 1.1125e-01  \n",
            "nt_epoch =   1770  elapsed = 17:42 (+26.4)  loss = 1.1095e-01  \n",
            "nt_epoch =   1780  elapsed = 18:08 (+26.4)  loss = 1.1063e-01  \n",
            "nt_epoch =   1790  elapsed = 18:35 (+26.4)  loss = 1.1053e-01  \n",
            "nt_epoch =   1800  elapsed = 19:01 (+26.4)  loss = 1.1040e-01  \n",
            "nt_epoch =   1810  elapsed = 19:28 (+26.5)  loss = 1.1027e-01  \n",
            "nt_epoch =   1820  elapsed = 19:54 (+26.5)  loss = 1.1044e-01  \n",
            "nt_epoch =   1830  elapsed = 20:21 (+26.5)  loss = 1.1046e-01  \n",
            "nt_epoch =   1840  elapsed = 20:47 (+26.5)  loss = 1.0993e-01  \n",
            "nt_epoch =   1850  elapsed = 21:14 (+26.5)  loss = 1.1014e-01  \n",
            "nt_epoch =   1860  elapsed = 21:40 (+26.5)  loss = 1.0963e-01  \n",
            "nt_epoch =   1870  elapsed = 22:07 (+26.7)  loss = 1.0954e-01  \n",
            "nt_epoch =   1880  elapsed = 22:34 (+26.3)  loss = 1.0952e-01  \n",
            "nt_epoch =   1890  elapsed = 23:00 (+26.3)  loss = 1.0952e-01  \n",
            "nt_epoch =   1900  elapsed = 23:26 (+26.3)  loss = 1.0944e-01  \n",
            "nt_epoch =   1910  elapsed = 23:53 (+26.3)  loss = 1.0922e-01  \n",
            "nt_epoch =   1920  elapsed = 24:19 (+26.6)  loss = 1.0901e-01  \n",
            "nt_epoch =   1930  elapsed = 24:46 (+26.7)  loss = 1.0899e-01  \n",
            "nt_epoch =   1940  elapsed = 25:13 (+26.8)  loss = 1.0896e-01  \n",
            "nt_epoch =   1950  elapsed = 25:40 (+26.6)  loss = 1.0894e-01  \n",
            "nt_epoch =   1960  elapsed = 26:06 (+26.4)  loss = 1.0892e-01  \n",
            "nt_epoch =   1970  elapsed = 26:33 (+26.5)  loss = 1.0883e-01  \n",
            "nt_epoch =   1980  elapsed = 26:59 (+26.7)  loss = 1.0839e-01  \n",
            "nt_epoch =   1990  elapsed = 27:27 (+27.1)  loss = 1.0836e-01  \n",
            "nt_epoch =   2000  elapsed = 27:53 (+26.8)  loss = 1.0834e-01  \n",
            "nt_epoch =   2010  elapsed = 28:20 (+26.5)  loss = 1.0823e-01  \n",
            "nt_epoch =   2020  elapsed = 28:47 (+26.5)  loss = 1.0816e-01  \n",
            "nt_epoch =   2030  elapsed = 29:13 (+26.6)  loss = 1.0829e-01  \n",
            "nt_epoch =   2040  elapsed = 29:40 (+26.8)  loss = 1.0794e-01  \n",
            "nt_epoch =   2050  elapsed = 30:07 (+26.7)  loss = 1.0767e-01  \n",
            "nt_epoch =   2060  elapsed = 30:34 (+26.8)  loss = 1.0747e-01  \n",
            "nt_epoch =   2070  elapsed = 31:00 (+26.3)  loss = 1.0738e-01  \n",
            "nt_epoch =   2080  elapsed = 31:26 (+26.3)  loss = 1.0731e-01  \n",
            "nt_epoch =   2090  elapsed = 31:53 (+26.5)  loss = 1.0723e-01  \n",
            "nt_epoch =   2100  elapsed = 32:19 (+26.4)  loss = 1.0736e-01  \n",
            "nt_epoch =   2110  elapsed = 32:46 (+26.4)  loss = 1.0715e-01  \n",
            "nt_epoch =   2120  elapsed = 33:12 (+26.5)  loss = 1.0710e-01  \n",
            "nt_epoch =   2130  elapsed = 33:39 (+26.6)  loss = 1.0705e-01  \n",
            "nt_epoch =   2140  elapsed = 34:05 (+26.3)  loss = 1.0701e-01  \n",
            "nt_epoch =   2150  elapsed = 34:32 (+26.5)  loss = 1.0695e-01  \n",
            "nt_epoch =   2160  elapsed = 34:58 (+26.4)  loss = 1.0689e-01  \n",
            "nt_epoch =   2170  elapsed = 35:25 (+26.5)  loss = 1.0686e-01  \n",
            "nt_epoch =   2180  elapsed = 35:51 (+26.3)  loss = 1.0678e-01  \n",
            "nt_epoch =   2190  elapsed = 36:18 (+26.8)  loss = 1.0668e-01  \n",
            "nt_epoch =   2200  elapsed = 36:45 (+26.7)  loss = 1.0662e-01  \n",
            "nt_epoch =   2210  elapsed = 37:11 (+26.6)  loss = 1.0655e-01  \n",
            "nt_epoch =   2220  elapsed = 37:38 (+26.6)  loss = 1.0638e-01  \n",
            "nt_epoch =   2230  elapsed = 38:05 (+26.8)  loss = 1.0622e-01  \n",
            "nt_epoch =   2240  elapsed = 38:31 (+26.5)  loss = 1.0642e-01  \n",
            "nt_epoch =   2250  elapsed = 38:58 (+26.6)  loss = 1.0603e-01  \n",
            "nt_epoch =   2260  elapsed = 39:25 (+26.7)  loss = 1.0574e-01  \n",
            "nt_epoch =   2270  elapsed = 39:52 (+26.7)  loss = 1.0543e-01  \n",
            "nt_epoch =   2280  elapsed = 40:18 (+26.7)  loss = 1.0519e-01  \n",
            "nt_epoch =   2290  elapsed = 40:45 (+26.5)  loss = 1.0507e-01  \n",
            "nt_epoch =   2300  elapsed = 41:11 (+26.4)  loss = 1.0486e-01  \n",
            "nt_epoch =   2310  elapsed = 41:38 (+26.3)  loss = 1.0465e-01  \n",
            "nt_epoch =   2320  elapsed = 42:04 (+26.1)  loss = 1.0452e-01  \n",
            "nt_epoch =   2330  elapsed = 42:30 (+26.2)  loss = 1.0435e-01  \n",
            "nt_epoch =   2340  elapsed = 42:57 (+26.5)  loss = 1.0461e-01  \n",
            "nt_epoch =   2350  elapsed = 43:23 (+26.4)  loss = 1.0405e-01  \n",
            "nt_epoch =   2360  elapsed = 43:49 (+26.4)  loss = 1.0394e-01  \n",
            "nt_epoch =   2370  elapsed = 44:16 (+26.6)  loss = 1.0356e-01  \n",
            "nt_epoch =   2380  elapsed = 44:43 (+26.6)  loss = 1.0330e-01  \n",
            "nt_epoch =   2390  elapsed = 45:09 (+26.7)  loss = 1.0307e-01  \n",
            "nt_epoch =   2400  elapsed = 45:36 (+26.8)  loss = 1.0269e-01  \n",
            "nt_epoch =   2410  elapsed = 46:03 (+26.5)  loss = 1.0245e-01  \n",
            "nt_epoch =   2420  elapsed = 46:30 (+26.6)  loss = 1.0212e-01  \n",
            "nt_epoch =   2430  elapsed = 46:56 (+26.6)  loss = 1.0186e-01  \n",
            "nt_epoch =   2440  elapsed = 47:23 (+26.8)  loss = 1.0100e-01  \n",
            "nt_epoch =   2450  elapsed = 47:50 (+26.5)  loss = 1.0025e-01  \n",
            "nt_epoch =   2460  elapsed = 48:16 (+26.5)  loss = 9.9922e-02  \n",
            "nt_epoch =   2470  elapsed = 48:43 (+26.4)  loss = 1.0076e-01  \n",
            "nt_epoch =   2480  elapsed = 49:09 (+26.4)  loss = 9.9557e-02  \n",
            "nt_epoch =   2490  elapsed = 49:36 (+26.5)  loss = 9.9294e-02  \n",
            "nt_epoch =   2500  elapsed = 50:02 (+26.2)  loss = 9.9000e-02  \n",
            "nt_epoch =   2510  elapsed = 50:28 (+26.4)  loss = 9.9841e-02  \n",
            "nt_epoch =   2520  elapsed = 50:55 (+26.6)  loss = 9.8531e-02  \n",
            "nt_epoch =   2530  elapsed = 51:22 (+26.7)  loss = 9.8427e-02  \n",
            "nt_epoch =   2540  elapsed = 51:48 (+26.7)  loss = 9.8395e-02  \n",
            "nt_epoch =   2550  elapsed = 52:15 (+27.0)  loss = 9.8191e-02  \n",
            "nt_epoch =   2560  elapsed = 52:42 (+26.8)  loss = 9.8049e-02  \n",
            "nt_epoch =   2570  elapsed = 53:09 (+26.5)  loss = 9.8810e-02  \n",
            "nt_epoch =   2580  elapsed = 53:36 (+26.6)  loss = 9.7842e-02  \n",
            "nt_epoch =   2590  elapsed = 54:02 (+26.5)  loss = 9.7545e-02  \n",
            "nt_epoch =   2600  elapsed = 54:29 (+26.7)  loss = 9.7390e-02  \n",
            "nt_epoch =   2610  elapsed = 54:55 (+26.4)  loss = 9.7339e-02  \n",
            "nt_epoch =   2620  elapsed = 55:22 (+26.6)  loss = 9.7014e-02  \n",
            "nt_epoch =   2630  elapsed = 55:48 (+26.4)  loss = 9.6748e-02  \n",
            "nt_epoch =   2640  elapsed = 56:15 (+26.6)  loss = 9.6379e-02  \n",
            "nt_epoch =   2650  elapsed = 56:42 (+26.7)  loss = 9.6195e-02  \n",
            "nt_epoch =   2660  elapsed = 57:09 (+26.8)  loss = 9.5830e-02  \n",
            "nt_epoch =   2670  elapsed = 57:36 (+26.8)  loss = 9.5603e-02  \n",
            "nt_epoch =   2680  elapsed = 58:02 (+26.7)  loss = 9.5480e-02  \n",
            "nt_epoch =   2690  elapsed = 58:29 (+26.7)  loss = 9.5341e-02  \n",
            "nt_epoch =   2700  elapsed = 58:56 (+26.7)  loss = 9.5412e-02  \n",
            "nt_epoch =   2710  elapsed = 59:23 (+26.9)  loss = 9.4961e-02  \n",
            "nt_epoch =   2720  elapsed = 59:50 (+26.6)  loss = 9.4752e-02  \n",
            "nt_epoch =   2730  elapsed = 00:16 (+26.7)  loss = 9.4420e-02  \n",
            "nt_epoch =   2740  elapsed = 00:43 (+26.5)  loss = 9.3952e-02  \n",
            "nt_epoch =   2750  elapsed = 01:10 (+26.7)  loss = 9.3621e-02  \n",
            "nt_epoch =   2760  elapsed = 01:37 (+26.8)  loss = 9.3579e-02  \n",
            "nt_epoch =   2770  elapsed = 02:03 (+26.9)  loss = 9.3201e-02  \n",
            "nt_epoch =   2780  elapsed = 02:30 (+26.8)  loss = 9.3064e-02  \n",
            "nt_epoch =   2790  elapsed = 02:57 (+26.7)  loss = 9.3747e-02  \n",
            "nt_epoch =   2800  elapsed = 03:24 (+26.9)  loss = 9.2679e-02  \n",
            "nt_epoch =   2810  elapsed = 03:51 (+26.9)  loss = 9.2543e-02  \n",
            "nt_epoch =   2820  elapsed = 04:18 (+27.1)  loss = 9.2020e-02  \n",
            "nt_epoch =   2830  elapsed = 04:45 (+26.9)  loss = 9.2291e-02  \n",
            "nt_epoch =   2840  elapsed = 05:12 (+26.8)  loss = 9.1635e-02  \n",
            "nt_epoch =   2850  elapsed = 05:39 (+26.7)  loss = 9.1307e-02  \n",
            "nt_epoch =   2860  elapsed = 06:05 (+26.7)  loss = 9.1322e-02  \n",
            "nt_epoch =   2870  elapsed = 06:32 (+26.8)  loss = 9.0786e-02  \n",
            "nt_epoch =   2880  elapsed = 06:59 (+26.7)  loss = 9.0658e-02  \n",
            "nt_epoch =   2890  elapsed = 07:26 (+26.8)  loss = 9.0801e-02  \n",
            "nt_epoch =   2900  elapsed = 07:52 (+26.7)  loss = 9.0371e-02  \n",
            "nt_epoch =   2910  elapsed = 08:19 (+26.6)  loss = 9.0608e-02  \n",
            "nt_epoch =   2920  elapsed = 08:46 (+27.3)  loss = 9.0332e-02  \n",
            "nt_epoch =   2930  elapsed = 09:13 (+26.9)  loss = 9.0185e-02  \n",
            "nt_epoch =   2940  elapsed = 09:41 (+27.1)  loss = 8.9889e-02  \n",
            "nt_epoch =   2950  elapsed = 10:07 (+26.7)  loss = 9.0879e-02  \n",
            "nt_epoch =   2960  elapsed = 10:34 (+26.8)  loss = 8.9422e-02  \n",
            "nt_epoch =   2970  elapsed = 11:01 (+26.9)  loss = 8.8945e-02  \n",
            "nt_epoch =   2980  elapsed = 11:28 (+26.8)  loss = 8.8806e-02  \n",
            "nt_epoch =   2990  elapsed = 11:55 (+26.9)  loss = 8.8764e-02  \n",
            "nt_epoch =   3000  elapsed = 12:22 (+26.7)  loss = 8.8785e-02  \n",
            "nt_epoch =   3010  elapsed = 12:49 (+26.8)  loss = 8.8593e-02  \n",
            "nt_epoch =   3020  elapsed = 13:15 (+26.7)  loss = 8.8410e-02  \n",
            "nt_epoch =   3030  elapsed = 13:42 (+26.6)  loss = 8.8116e-02  \n",
            "nt_epoch =   3040  elapsed = 14:08 (+26.4)  loss = 8.7680e-02  \n",
            "nt_epoch =   3050  elapsed = 14:35 (+26.4)  loss = 8.7419e-02  \n",
            "nt_epoch =   3060  elapsed = 15:02 (+26.8)  loss = 8.6944e-02  \n",
            "nt_epoch =   3070  elapsed = 15:28 (+26.5)  loss = 8.6894e-02  \n",
            "nt_epoch =   3080  elapsed = 15:55 (+26.6)  loss = 8.6812e-02  \n",
            "nt_epoch =   3090  elapsed = 16:22 (+26.7)  loss = 8.6864e-02  \n",
            "nt_epoch =   3100  elapsed = 16:48 (+26.4)  loss = 8.6658e-02  \n",
            "nt_epoch =   3110  elapsed = 17:15 (+26.8)  loss = 8.6706e-02  \n",
            "nt_epoch =   3120  elapsed = 17:42 (+26.8)  loss = 8.6560e-02  \n",
            "nt_epoch =   3130  elapsed = 18:09 (+26.7)  loss = 8.6498e-02  \n",
            "nt_epoch =   3140  elapsed = 18:35 (+26.6)  loss = 8.6450e-02  \n",
            "nt_epoch =   3150  elapsed = 19:02 (+26.8)  loss = 8.6852e-02  \n",
            "nt_epoch =   3160  elapsed = 19:29 (+27.0)  loss = 8.5590e-02  \n",
            "nt_epoch =   3170  elapsed = 19:56 (+26.9)  loss = 8.5437e-02  \n",
            "nt_epoch =   3180  elapsed = 20:23 (+27.2)  loss = 8.5282e-02  \n",
            "nt_epoch =   3190  elapsed = 20:50 (+26.9)  loss = 8.5079e-02  \n",
            "nt_epoch =   3200  elapsed = 21:18 (+27.3)  loss = 8.4844e-02  \n",
            "nt_epoch =   3210  elapsed = 21:45 (+26.9)  loss = 8.4730e-02  \n",
            "nt_epoch =   3220  elapsed = 22:12 (+27.0)  loss = 8.4721e-02  \n",
            "nt_epoch =   3230  elapsed = 22:39 (+27.2)  loss = 8.4587e-02  \n",
            "nt_epoch =   3240  elapsed = 23:06 (+26.7)  loss = 8.4820e-02  \n",
            "nt_epoch =   3250  elapsed = 23:32 (+26.8)  loss = 8.4297e-02  \n",
            "nt_epoch =   3260  elapsed = 23:59 (+26.6)  loss = 8.4473e-02  \n",
            "nt_epoch =   3270  elapsed = 24:26 (+26.7)  loss = 8.3755e-02  \n",
            "nt_epoch =   3280  elapsed = 24:52 (+26.5)  loss = 8.3472e-02  \n",
            "nt_epoch =   3290  elapsed = 25:19 (+26.6)  loss = 8.3364e-02  \n",
            "nt_epoch =   3300  elapsed = 25:46 (+26.8)  loss = 8.3269e-02  \n",
            "nt_epoch =   3310  elapsed = 26:13 (+26.6)  loss = 8.3172e-02  \n",
            "nt_epoch =   3320  elapsed = 26:39 (+26.7)  loss = 8.3120e-02  \n",
            "nt_epoch =   3330  elapsed = 27:06 (+26.6)  loss = 8.2933e-02  \n",
            "nt_epoch =   3340  elapsed = 27:33 (+26.8)  loss = 8.2817e-02  \n",
            "nt_epoch =   3350  elapsed = 28:00 (+26.6)  loss = 8.2726e-02  \n",
            "nt_epoch =   3360  elapsed = 28:26 (+26.9)  loss = 8.2636e-02  \n",
            "nt_epoch =   3370  elapsed = 28:53 (+27.0)  loss = 8.3261e-02  \n",
            "nt_epoch =   3380  elapsed = 29:21 (+27.1)  loss = 8.2179e-02  \n",
            "nt_epoch =   3390  elapsed = 29:48 (+26.9)  loss = 8.2089e-02  \n",
            "nt_epoch =   3400  elapsed = 30:14 (+26.7)  loss = 8.2137e-02  \n",
            "nt_epoch =   3410  elapsed = 30:41 (+26.7)  loss = 8.1900e-02  \n",
            "nt_epoch =   3420  elapsed = 31:08 (+27.1)  loss = 8.1682e-02  \n",
            "nt_epoch =   3430  elapsed = 31:35 (+26.8)  loss = 8.1471e-02  \n",
            "nt_epoch =   3440  elapsed = 32:02 (+26.9)  loss = 8.1337e-02  \n",
            "nt_epoch =   3450  elapsed = 32:29 (+26.9)  loss = 8.1229e-02  \n",
            "nt_epoch =   3460  elapsed = 32:56 (+26.7)  loss = 8.1182e-02  \n",
            "nt_epoch =   3470  elapsed = 33:23 (+26.9)  loss = 8.1007e-02  \n",
            "nt_epoch =   3480  elapsed = 33:50 (+27.0)  loss = 8.0669e-02  \n",
            "nt_epoch =   3490  elapsed = 34:17 (+26.8)  loss = 8.0448e-02  \n",
            "nt_epoch =   3500  elapsed = 34:43 (+26.7)  loss = 8.0667e-02  \n",
            "nt_epoch =   3510  elapsed = 35:10 (+26.7)  loss = 8.0282e-02  \n",
            "nt_epoch =   3520  elapsed = 35:37 (+26.9)  loss = 7.9813e-02  \n",
            "nt_epoch =   3530  elapsed = 36:04 (+27.2)  loss = 7.9680e-02  \n",
            "nt_epoch =   3540  elapsed = 36:32 (+27.3)  loss = 7.9595e-02  \n",
            "nt_epoch =   3550  elapsed = 36:59 (+26.9)  loss = 7.9494e-02  \n",
            "nt_epoch =   3560  elapsed = 37:26 (+27.0)  loss = 7.9334e-02  \n",
            "nt_epoch =   3570  elapsed = 37:52 (+26.6)  loss = 7.9312e-02  \n",
            "nt_epoch =   3580  elapsed = 38:19 (+26.8)  loss = 7.9182e-02  \n",
            "nt_epoch =   3590  elapsed = 38:46 (+26.8)  loss = 7.9099e-02  \n",
            "nt_epoch =   3600  elapsed = 39:13 (+27.0)  loss = 7.9040e-02  \n",
            "nt_epoch =   3610  elapsed = 39:40 (+27.2)  loss = 7.8833e-02  \n",
            "nt_epoch =   3620  elapsed = 40:08 (+27.3)  loss = 7.8577e-02  \n",
            "nt_epoch =   3630  elapsed = 40:35 (+27.2)  loss = 7.8538e-02  \n",
            "nt_epoch =   3640  elapsed = 41:03 (+27.7)  loss = 7.8441e-02  \n",
            "nt_epoch =   3650  elapsed = 41:30 (+27.3)  loss = 7.8411e-02  \n",
            "nt_epoch =   3660  elapsed = 41:57 (+27.1)  loss = 7.8243e-02  \n",
            "nt_epoch =   3670  elapsed = 42:24 (+26.9)  loss = 7.7824e-02  \n",
            "nt_epoch =   3680  elapsed = 42:51 (+27.0)  loss = 7.7591e-02  \n",
            "nt_epoch =   3690  elapsed = 43:19 (+27.2)  loss = 7.7391e-02  \n",
            "nt_epoch =   3700  elapsed = 43:46 (+27.2)  loss = 7.7080e-02  \n",
            "nt_epoch =   3710  elapsed = 44:13 (+27.2)  loss = 7.7365e-02  \n",
            "nt_epoch =   3720  elapsed = 44:40 (+27.4)  loss = 7.6779e-02  \n",
            "nt_epoch =   3730  elapsed = 45:08 (+27.8)  loss = 7.6893e-02  \n",
            "nt_epoch =   3740  elapsed = 45:35 (+27.2)  loss = 7.6403e-02  \n",
            "nt_epoch =   3750  elapsed = 46:03 (+27.1)  loss = 7.6234e-02  \n",
            "nt_epoch =   3760  elapsed = 46:30 (+27.0)  loss = 7.6109e-02  \n",
            "nt_epoch =   3770  elapsed = 46:57 (+27.4)  loss = 7.5958e-02  \n",
            "nt_epoch =   3780  elapsed = 47:25 (+27.4)  loss = 7.5879e-02  \n",
            "nt_epoch =   3790  elapsed = 47:52 (+27.2)  loss = 7.5688e-02  \n",
            "nt_epoch =   3800  elapsed = 48:19 (+27.0)  loss = 7.5595e-02  \n",
            "nt_epoch =   3810  elapsed = 48:46 (+26.8)  loss = 7.5591e-02  \n",
            "nt_epoch =   3820  elapsed = 49:13 (+27.1)  loss = 7.5506e-02  \n",
            "nt_epoch =   3830  elapsed = 49:40 (+26.9)  loss = 7.5442e-02  \n",
            "nt_epoch =   3840  elapsed = 50:07 (+26.7)  loss = 7.5129e-02  \n",
            "nt_epoch =   3850  elapsed = 50:34 (+26.9)  loss = 7.4831e-02  \n",
            "nt_epoch =   3860  elapsed = 51:01 (+27.0)  loss = 7.4733e-02  \n",
            "nt_epoch =   3870  elapsed = 51:28 (+27.2)  loss = 7.4615e-02  \n",
            "nt_epoch =   3880  elapsed = 51:55 (+27.3)  loss = 7.4526e-02  \n",
            "nt_epoch =   3890  elapsed = 52:23 (+27.3)  loss = 7.4426e-02  \n",
            "nt_epoch =   3900  elapsed = 52:49 (+26.9)  loss = 7.4644e-02  \n",
            "nt_epoch =   3910  elapsed = 53:17 (+27.0)  loss = 7.4339e-02  \n",
            "nt_epoch =   3920  elapsed = 53:43 (+26.8)  loss = 7.4239e-02  \n",
            "nt_epoch =   3930  elapsed = 54:10 (+26.8)  loss = 7.4100e-02  \n",
            "nt_epoch =   3940  elapsed = 54:37 (+27.0)  loss = 7.3926e-02  \n",
            "nt_epoch =   3950  elapsed = 55:04 (+26.8)  loss = 7.5215e-02  \n",
            "nt_epoch =   3960  elapsed = 55:31 (+26.7)  loss = 7.3498e-02  \n",
            "nt_epoch =   3970  elapsed = 55:58 (+26.7)  loss = 7.3503e-02  \n",
            "nt_epoch =   3980  elapsed = 56:25 (+27.0)  loss = 7.3244e-02  \n",
            "nt_epoch =   3990  elapsed = 56:52 (+27.0)  loss = 7.3944e-02  \n",
            "nt_epoch =   4000  elapsed = 57:19 (+27.0)  loss = 7.2895e-02  \n",
            "nt_epoch =   4010  elapsed = 57:46 (+27.2)  loss = 7.2776e-02  \n",
            "nt_epoch =   4020  elapsed = 58:13 (+26.9)  loss = 7.2544e-02  \n",
            "nt_epoch =   4030  elapsed = 58:40 (+26.9)  loss = 7.2359e-02  \n",
            "nt_epoch =   4040  elapsed = 59:07 (+26.9)  loss = 7.2209e-02  \n",
            "nt_epoch =   4050  elapsed = 59:34 (+26.9)  loss = 7.2514e-02  \n",
            "nt_epoch =   4060  elapsed = 00:01 (+26.8)  loss = 7.1986e-02  \n",
            "nt_epoch =   4070  elapsed = 00:27 (+26.8)  loss = 7.1880e-02  \n",
            "nt_epoch =   4080  elapsed = 00:54 (+26.8)  loss = 7.2064e-02  \n",
            "nt_epoch =   4090  elapsed = 01:21 (+26.8)  loss = 7.1593e-02  \n",
            "nt_epoch =   4100  elapsed = 01:48 (+26.9)  loss = 7.1523e-02  \n",
            "nt_epoch =   4110  elapsed = 02:15 (+26.9)  loss = 7.1499e-02  \n",
            "nt_epoch =   4120  elapsed = 02:42 (+26.9)  loss = 7.1890e-02  \n",
            "nt_epoch =   4130  elapsed = 03:09 (+27.3)  loss = 7.0994e-02  \n",
            "nt_epoch =   4140  elapsed = 03:36 (+27.0)  loss = 7.1119e-02  \n",
            "nt_epoch =   4150  elapsed = 04:03 (+27.0)  loss = 7.0456e-02  \n",
            "nt_epoch =   4160  elapsed = 04:31 (+27.1)  loss = 7.0188e-02  \n",
            "nt_epoch =   4170  elapsed = 04:58 (+27.1)  loss = 6.9895e-02  \n",
            "nt_epoch =   4180  elapsed = 05:26 (+27.8)  loss = 6.9716e-02  \n",
            "nt_epoch =   4190  elapsed = 05:53 (+27.1)  loss = 6.9564e-02  \n",
            "nt_epoch =   4200  elapsed = 06:20 (+27.1)  loss = 7.0007e-02  \n",
            "nt_epoch =   4210  elapsed = 06:47 (+27.1)  loss = 6.9660e-02  \n",
            "nt_epoch =   4220  elapsed = 07:14 (+27.2)  loss = 6.9169e-02  \n",
            "nt_epoch =   4230  elapsed = 07:42 (+27.1)  loss = 6.9019e-02  \n",
            "nt_epoch =   4240  elapsed = 08:09 (+27.0)  loss = 6.8947e-02  \n",
            "nt_epoch =   4250  elapsed = 08:36 (+27.0)  loss = 6.8725e-02  \n",
            "nt_epoch =   4260  elapsed = 09:03 (+27.1)  loss = 6.8610e-02  \n",
            "nt_epoch =   4270  elapsed = 09:30 (+27.6)  loss = 6.8324e-02  \n",
            "nt_epoch =   4280  elapsed = 09:57 (+26.5)  loss = 6.8047e-02  \n",
            "nt_epoch =   4290  elapsed = 10:24 (+26.7)  loss = 6.7939e-02  \n",
            "nt_epoch =   4300  elapsed = 10:50 (+26.6)  loss = 6.7794e-02  \n",
            "nt_epoch =   4310  elapsed = 11:17 (+26.9)  loss = 6.7696e-02  \n",
            "nt_epoch =   4320  elapsed = 11:44 (+27.1)  loss = 6.7738e-02  \n",
            "nt_epoch =   4330  elapsed = 12:12 (+27.1)  loss = 6.7412e-02  \n",
            "nt_epoch =   4340  elapsed = 12:38 (+26.8)  loss = 6.7261e-02  \n",
            "nt_epoch =   4350  elapsed = 13:05 (+26.9)  loss = 6.6958e-02  \n",
            "nt_epoch =   4360  elapsed = 13:33 (+27.0)  loss = 6.7141e-02  \n",
            "nt_epoch =   4370  elapsed = 13:59 (+26.5)  loss = 6.6557e-02  \n",
            "nt_epoch =   4380  elapsed = 14:26 (+26.6)  loss = 6.6078e-02  \n",
            "nt_epoch =   4390  elapsed = 14:52 (+26.6)  loss = 6.5710e-02  \n",
            "nt_epoch =   4400  elapsed = 15:19 (+27.0)  loss = 6.5526e-02  \n",
            "nt_epoch =   4410  elapsed = 15:46 (+26.8)  loss = 6.5463e-02  \n",
            "nt_epoch =   4420  elapsed = 16:13 (+27.0)  loss = 6.5338e-02  \n",
            "nt_epoch =   4430  elapsed = 16:40 (+27.1)  loss = 6.5209e-02  \n",
            "nt_epoch =   4440  elapsed = 17:10 (+29.1)  loss = 6.5669e-02  \n",
            "nt_epoch =   4450  elapsed = 17:37 (+27.7)  loss = 6.4585e-02  \n",
            "nt_epoch =   4460  elapsed = 18:04 (+26.9)  loss = 6.4362e-02  \n",
            "nt_epoch =   4470  elapsed = 18:31 (+26.9)  loss = 6.4343e-02  \n",
            "nt_epoch =   4480  elapsed = 18:58 (+27.1)  loss = 6.4060e-02  \n",
            "nt_epoch =   4490  elapsed = 19:25 (+26.9)  loss = 6.4116e-02  \n",
            "nt_epoch =   4500  elapsed = 19:52 (+26.7)  loss = 6.3854e-02  \n",
            "nt_epoch =   4510  elapsed = 20:19 (+27.2)  loss = 6.3906e-02  \n",
            "nt_epoch =   4520  elapsed = 20:46 (+27.0)  loss = 6.3562e-02  \n",
            "nt_epoch =   4530  elapsed = 21:13 (+27.1)  loss = 6.3471e-02  \n",
            "nt_epoch =   4540  elapsed = 21:41 (+27.1)  loss = 6.3374e-02  \n",
            "nt_epoch =   4550  elapsed = 22:08 (+27.1)  loss = 6.3307e-02  \n",
            "nt_epoch =   4560  elapsed = 22:35 (+27.1)  loss = 6.3134e-02  \n",
            "nt_epoch =   4570  elapsed = 23:02 (+26.8)  loss = 6.3069e-02  \n",
            "nt_epoch =   4580  elapsed = 23:29 (+27.0)  loss = 6.2709e-02  \n",
            "nt_epoch =   4590  elapsed = 23:56 (+26.9)  loss = 6.2457e-02  \n",
            "nt_epoch =   4600  elapsed = 24:23 (+27.2)  loss = 6.2259e-02  \n",
            "nt_epoch =   4610  elapsed = 24:50 (+26.8)  loss = 6.2409e-02  \n",
            "nt_epoch =   4620  elapsed = 25:17 (+26.8)  loss = 6.2043e-02  \n",
            "nt_epoch =   4630  elapsed = 25:44 (+26.9)  loss = 6.1940e-02  \n",
            "nt_epoch =   4640  elapsed = 26:10 (+26.7)  loss = 6.1797e-02  \n",
            "nt_epoch =   4650  elapsed = 26:37 (+27.1)  loss = 6.1499e-02  \n",
            "nt_epoch =   4660  elapsed = 27:04 (+27.0)  loss = 6.1208e-02  \n",
            "nt_epoch =   4670  elapsed = 27:32 (+27.1)  loss = 6.1058e-02  \n",
            "nt_epoch =   4680  elapsed = 27:59 (+27.1)  loss = 6.1197e-02  \n",
            "nt_epoch =   4690  elapsed = 28:26 (+27.2)  loss = 6.0843e-02  \n",
            "nt_epoch =   4700  elapsed = 28:53 (+27.1)  loss = 6.0539e-02  \n",
            "nt_epoch =   4710  elapsed = 29:21 (+27.4)  loss = 6.0403e-02  \n",
            "nt_epoch =   4720  elapsed = 29:48 (+27.3)  loss = 6.0289e-02  \n",
            "nt_epoch =   4730  elapsed = 30:15 (+26.8)  loss = 6.0325e-02  \n",
            "nt_epoch =   4740  elapsed = 30:42 (+26.8)  loss = 6.0101e-02  \n",
            "nt_epoch =   4750  elapsed = 31:09 (+26.8)  loss = 6.0168e-02  \n",
            "nt_epoch =   4760  elapsed = 31:35 (+26.8)  loss = 5.9850e-02  \n",
            "nt_epoch =   4770  elapsed = 32:02 (+26.5)  loss = 5.9731e-02  \n",
            "nt_epoch =   4780  elapsed = 32:29 (+27.0)  loss = 5.9444e-02  \n",
            "nt_epoch =   4790  elapsed = 32:56 (+27.0)  loss = 5.9287e-02  \n",
            "nt_epoch =   4800  elapsed = 33:23 (+27.4)  loss = 5.9091e-02  \n",
            "nt_epoch =   4810  elapsed = 33:51 (+27.2)  loss = 5.8958e-02  \n",
            "nt_epoch =   4820  elapsed = 34:18 (+27.0)  loss = 5.8806e-02  \n",
            "nt_epoch =   4830  elapsed = 34:45 (+27.2)  loss = 5.8646e-02  \n",
            "nt_epoch =   4840  elapsed = 35:12 (+27.3)  loss = 5.8533e-02  \n",
            "nt_epoch =   4850  elapsed = 35:39 (+27.2)  loss = 5.8440e-02  \n",
            "nt_epoch =   4860  elapsed = 36:07 (+27.2)  loss = 5.8187e-02  \n",
            "nt_epoch =   4870  elapsed = 36:34 (+27.2)  loss = 5.8109e-02  \n",
            "nt_epoch =   4880  elapsed = 37:01 (+26.9)  loss = 5.7996e-02  \n",
            "nt_epoch =   4890  elapsed = 37:28 (+27.3)  loss = 5.7843e-02  \n",
            "nt_epoch =   4900  elapsed = 37:55 (+27.1)  loss = 5.7748e-02  \n",
            "nt_epoch =   4910  elapsed = 38:22 (+26.8)  loss = 5.7819e-02  \n",
            "nt_epoch =   4920  elapsed = 38:49 (+26.9)  loss = 5.7487e-02  \n",
            "nt_epoch =   4930  elapsed = 39:16 (+27.0)  loss = 5.7349e-02  \n",
            "nt_epoch =   4940  elapsed = 39:43 (+27.0)  loss = 5.7150e-02  \n",
            "nt_epoch =   4950  elapsed = 40:11 (+27.1)  loss = 5.6955e-02  \n",
            "L-BFGS Results\n",
            "Converged: tf.Tensor(False, shape=(), dtype=bool)\n",
            "Location of the minimum: tf.Tensor(\n",
            "[ 0.16980193 -0.01929505 -0.04786124 ...  0.08995757  1.23140916\n",
            "  0.25799044], shape=(2008,), dtype=float64)\n",
            "Number of iterations: tf.Tensor(1500, shape=(), dtype=int32)\n",
            "==================\n",
            "Training finished (epochs 2500): duration = 40:11  \n",
            "Error u: 8.413897e-01\n",
            "Error v: 1.113505e+00\n",
            "Error h: 5.241777e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Mb-Txh1OQ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "531380d6-ba27-4526-bb2f-255354301469"
      },
      "source": [
        "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "V_pred = griddata(X_star, v_pred.flatten(), (X, T), method='cubic')\n",
        "H_pred = griddata(X_star, h_pred.flatten(), (X, T), method='cubic')\n",
        "\n",
        "X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
        "X_lb = np.concatenate((0*tb + lb[0], tb), 1) # (lb[0], tb)\n",
        "X_ub = np.concatenate((0*tb + ub[0], tb), 1) # (ub[0], tb)\n",
        "X_u_train = np.vstack([X0, X_lb, X_ub])\n",
        "#Se grafican los resultados\n",
        "fig = plt.figure()\n",
        "ax = plt.axis('off')\n",
        "gs0 = gridspec.GridSpec(1, 2)\n",
        "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
        "ax = plt.subplot(gs0[:, :])\n",
        "h = ax.imshow(H_pred.T, interpolation='nearest', cmap='YlGnBu', \n",
        "                  extent=[lb[1], ub[1], lb[0], ub[0]], \n",
        "                  origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (X_u_train.shape[0]), markersize = 4, clip_on = False)\n",
        "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "ax.plot(t[75]*np.ones((2,1)), line, 'k--', linewidth = 1)\n",
        "ax.plot(t[100]*np.ones((2,1)), line, 'k--', linewidth = 1)\n",
        "ax.plot(t[125]*np.ones((2,1)), line, 'k--', linewidth = 1)    \n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "leg = ax.legend(frameon=False, loc = 'best')\n",
        "ax.set_title('$|h(t,x)|$', fontsize = 10)\n",
        "gs1 = gridspec.GridSpec(1, 3)\n",
        "gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5) \n",
        "ax = plt.subplot(gs1[0, 0])\n",
        "ax.plot(x,Exact_h[:,75], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,H_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$|h(t,x)|$')    \n",
        "ax.set_title('$t = %.2f$' % (t[75]), fontsize = 10)\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-5.1,5.1])\n",
        "ax.set_ylim([-0.1,5.1])\n",
        "ax = plt.subplot(gs1[0, 1])\n",
        "ax.plot(x,Exact_h[:,100], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,H_pred[100,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$|h(t,x)|$')\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-5.1,5.1])\n",
        "ax.set_ylim([-0.1,5.1])\n",
        "ax.set_title('$t = %.2f$' % (t[100]), fontsize = 10)\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.8), ncol=5, frameon=False)\n",
        "ax = plt.subplot(gs1[0, 2])\n",
        "ax.plot(x,Exact_h[:,125], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,H_pred[125,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$|h(t,x)|$')\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-5.1,5.1])\n",
        "ax.set_ylim([-0.1,5.1])    \n",
        "ax.set_title('$t = %.2f$' % (t[125]), fontsize = 10)\n",
        "plt.savefig('NLS')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsUPdL5Gl1X6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "12dbd2a8-3243-4482-9c78-ed97b51a5c94"
      },
      "source": [
        "df_tf=pd.DataFrame(pinn.loss_train_tf)\n",
        "df_nt=pd.DataFrame(pinn.loss_train_nt)\n",
        "epochs_tf = df_tf[0]\n",
        "loss_tf = df_tf[1]\n",
        "epochs_nt = df_nt[0]\n",
        "loss_nt = df_nt[1]\n",
        "plt.plot(epochs_tf,loss_tf, label=\"ADAM\")\n",
        "plt.plot(epochs_nt,loss_nt, label=\"LBFGS\")\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteraciones')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('optimizacion')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}